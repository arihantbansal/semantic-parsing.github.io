<!DOCTYPE html>
<html lang="en-us">

  <head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-153224273-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-153224273-6');
  </script>

  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="keywords" content="semantic parsing, query languages, meaning representations, machine learning, discourse representations">

  <title>
    
      Search all Publications on Semantic Parsing &middot; Semantic Parsing
    
  </title>

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="shortcut icon" href="/public/favicon.svg">
  <link rel="search" href="/public/opensearchdescription.xml" 
      type="application/opensearchdescription+xml" 
      title="ML4Code" />

  <script src="https://code.jquery.com/jquery-3.2.1.min.js"
  integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4="
  crossorigin="anonymous"></script>
  
  <link rel="stylesheet" type="text/css" href="//cdn.datatables.net/1.10.16/css/jquery.dataTables.min.css">
  <script type="text/javascript" charset="utf8" src="//cdn.datatables.net/1.10.16/js/jquery.dataTables.min.js"></script>
</head>


  <body class="theme-base-07 layout-reverse">

    <a href='/contributing.html' class='ribbon'>Contribute to Semantic Parsing</a>
<div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/">
          Semantic Parsing
        </a>
      </h1>
      <p class="lead">Research on Modeling and Data resources for Semantic Parsing.</p>      
    </div>

  <nav class="sidebar-nav">
   <div class="sidebar-item"><p style="font-size: 12px">Search related work <input type='text' id='searchTarget' size="16"/> <button onClick="search();">Go</button></p></div>
   <a class="sidebar-nav-item active" href="/papers.html">List of Papers</a>
   <a class="sidebar-nav-item" href="/tags.html">Papers by Tag</a>
   <a class="sidebar-nav-item" href="/tsne-viz.html">2D Map of Papers</a>
   <a class="sidebar-nav-item" href="/topic-viz.html">Topic-based Explorer</a>

   <a class="sidebar-nav-item" href="/base-taxonomy/">Core Taxonomy</a>


  <a class="sidebar-nav-item" href="/resources.html">Resources, Courses &#38; Events</a>
  <a class="sidebar-nav-item" href="/contributing.html">Contributing</a>
  </nav>

  <div class="sidebar-item">
    <p style="font-size: 12px">Contact <a href="https://rajaswa.github.io/">Rajaswa Patil</a> about this survey or website.
    <span style="font-size: 9px">
      Made with <a href="https://jekyllrb.com">Jekyll</a> and <a href="https://github.com/poole/hyde">Hyde</a>.
    </span></p>
  </div>
</div></div>

<script>
$("#searchTarget").keydown(function (e) {	
  if (e.keyCode == 13) {
    search();
  }
});

function search() {
  try {
    ga('send', 'event', 'search', 'search', $("#searchTarget").val());
  } finally {
    window.location = "/papers.html#" + $("#searchTarget").val();
  }
}
</script>


    <div class="content container">
      Search across all paper titles, abstracts, authors by using the search field.
Please consider <a href="/contributing.html">contributing</a> by updating
the information of existing papers or adding new work.

<table id="allPapers">
<thead><th>Year</th><th>Title</th><th>Authors</th><th>Venue</th><th>Abstract</th></thead><tbody>



<tr>
	<td>2021</td>
	<td><a href="/publications/sherborne2021zero/">Zero-Shot Cross-lingual Semantic Parsing</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Zero-Shot Cross-lingual Semantic Parsing' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Zero-Shot Cross-lingual Semantic Parsing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Zero-Shot%20Cross-lingual%20Semantic%20Parsing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Tom Sherborne, Mirella Lapata</td>
	<td></td>
	<td><p>Recent work in crosslingual semantic parsing has successfully applied machine translation to localize accurate parsing to new languages. However, these advances assume access to high-quality machine translation systems, and tools such as word aligners, for all test languages. We remove these assumptions and study cross-lingual semantic parsing as a zero-shot problem without parallel data for 7 test languages (DE, ZH, FR, ES, PT, HI, TR). We propose a multi-task encoder-decoder model to transfer parsing knowledge to additional languages using only English-Logical form paired data and unlabeled, monolingual utterances in each test language. We train an encoder to generate language-agnostic representations jointly optimized for generating logical forms or utterance reconstruction and against language discriminability. Our system frames zero-shot parsing as a latent-space alignment problem and finds that pre-trained models can be improved to generate logical forms with minimal cross-lingual transfer penalty. Experimental results on Overnight and a new executable version of MultiATIS++ find that our zero-shot approach performs above back-translation baselines and, in some cases, approaches the supervised upper bound.</p>
</td>
	<td>sql cross-lingual multi-lingual transformer </td>
</tr>

<tr>
	<td>2021</td>
	<td><a href="/publications/hazoom2021text/">Text-to-SQL in the Wild: A Naturally-Occurring Dataset Based on Stack Exchange Data</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Text-to-SQL in the Wild: A Naturally-Occurring Dataset Based on Stack Exchange Data' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Text-to-SQL in the Wild: A Naturally-Occurring Dataset Based on Stack Exchange Data' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Text-to-SQL%20in%20the%20Wild:%20A%20Naturally-Occurring%20Dataset%20Based%20on%20Stack%20Exchange%20Data' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Moshe Hazoom, Vibhor Malik, Ben Bogin</td>
	<td>NLP4Prog</td>
	<td><p>Most available semantic parsing datasets, comprising of pairs of natural utterances and logical forms, were collected solely for the purpose of training and evaluation of natural language understanding systems. As a result, they do not contain any of the richness and variety of natural-occurring utterances, where humans ask about data they need or are curious about. In this work, we release SEDE, a dataset with 12,023 pairs of utterances and SQL queries collected from real usage on the Stack Exchange website. We show that these pairs contain a variety of real-world challenges which were rarely reflected so far in any other semantic parsing dataset, propose an evaluation metric based on comparison of partial query clauses that is more suitable for real-world queries, and conduct experiments with strong baselines, showing a large gap between the performance on SEDE compared to other common datasets.</p>
</td>
	<td>sql evaluation dataset </td>
</tr>

<tr>
	<td>2021</td>
	<td><a href="/publications/wang2021meta/">Meta-Learning for Domain Generalization in Semantic Parsing</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Meta-Learning for Domain Generalization in Semantic Parsing' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Meta-Learning for Domain Generalization in Semantic Parsing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Meta-Learning%20for%20Domain%20Generalization%20in%20Semantic%20Parsing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Bailin Wang, Mirella Lapata, Ivan Titov</td>
	<td>NAACL</td>
	<td><p>Recent work in crosslingual semantic parsing has successfully applied machine translation to localize accurate parsing to new languages. However, these advances assume access to high-quality machine translation systems, and tools such as word aligners, for all test languages. We remove these assumptions and study cross-lingual semantic parsing as a zero-shot problem without parallel data for 7 test languages (DE, ZH, FR, ES, PT, HI, TR). We propose a multi-task encoder-decoder model to transfer parsing knowledge to additional languages using only English-Logical form paired data and unlabeled, monolingual utterances in each test language. We train an encoder to generate language-agnostic representations jointly optimized for generating logical forms or utterance reconstruction and against language discriminability. Our system frames zero-shot parsing as a latent-space alignment problem and finds that pre-trained models can be improved to generate logical forms with minimal cross-lingual transfer penalty. Experimental results on Overnight and a new executable version of MultiATIS++ find that our zero-shot approach performs above back-translation baselines and, in some cases, approaches the supervised upper bound.</p>
</td>
	<td>sql meta-learning cross-domain transformer </td>
</tr>



<tr>
	<td>2020</td>
	<td><a href="/publications/elgohary2020speak/">Speak to your Parser: Interactive Text-to-SQL with Natural Language Feedback</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Speak to your Parser: Interactive Text-to-SQL with Natural Language Feedback' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Speak to your Parser: Interactive Text-to-SQL with Natural Language Feedback' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Speak%20to%20your%20Parser:%20Interactive%20Text-to-SQL%20with%20Natural%20Language%20Feedback' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Ahmed Elgohary, Saghar Hosseini, Ahmed Hassan Awadallah</td>
	<td>ACL</td>
	<td><p>We study the task of semantic parse correction with natural language feedback. Given a natural language utterance, most semantic parsing systems pose the problem as one-shot translation where the utterance is mapped to a corresponding logical form. In this paper, we investigate a more interactive scenario where humans can further interact with the system by providing free-form natural language feedback to correct the system when it generates an inaccurate interpretation of an initial utterance. We focus on natural language to SQL systems and construct, SPLASH, a dataset of utterances, incorrect SQL interpretations and the corresponding natural language feedback. We compare various reference models for the correction task and show that incorporating such a rich form of feedback can significantly improve the overall semantic parsing accuracy while retaining the flexibility of natural language interaction. While we estimated human correction accuracy is 81.5%, our best model achieves only 25.1%, which leaves a large gap for improvement in future research. SPLASH is publicly available at this URL: https://github.com/MSR-LIT/Splash</p>
</td>
	<td>sql conversational dataset </td>
</tr>

<tr>
	<td>2020</td>
	<td><a href="/publications/nguyen2020a/">A Pilot Study of Text-to-SQL Semantic Parsing for Vietnamese</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=A Pilot Study of Text-to-SQL Semantic Parsing for Vietnamese' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=A Pilot Study of Text-to-SQL Semantic Parsing for Vietnamese' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=A%20Pilot%20Study%20of%20Text-to-SQL%20Semantic%20Parsing%20for%20Vietnamese' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Anh Tuan Nguyen, Mai Hoang Dao, Dat Quoc Nguyen</td>
	<td>EMNLP</td>
	<td><p>Semantic parsing is an important NLP task. However, Vietnamese is a low-resource language in this research area. In this paper, we present the first public large-scale Text-to-SQL semantic parsing dataset for Vietnamese. We extend and evaluate two strong semantic parsing baselines EditSQL (Zhang et al., 2019) and IRNet (Guo et al., 2019) on our dataset. We compare the two baselines with key configurations and find that: automatic Vietnamese word segmentation improves the parsing results of both baselines; the normalized pointwise mutual information (NPMI) score (Bouma, 2009) is useful for schema linking; latent syntactic features extracted from a neural dependency parser for Vietnamese also improve the results; and the monolingual language model PhoBERT for Vietnamese (Nguyen and Nguyen, 2020) helps produce higher performances than the recent best multilingual language model XLM-R (Conneau et al., 2020).</p>
</td>
	<td>sql cross-domain dataset </td>
</tr>

<tr>
	<td>2020</td>
	<td><a href="/publications/zhang2020did/">Did You Ask a Good Question? A Cross-Domain Question Intention Classification Benchmark for Text-to-SQL</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Did You Ask a Good Question? A Cross-Domain Question Intention Classification Benchmark for Text-to-SQL' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Did You Ask a Good Question? A Cross-Domain Question Intention Classification Benchmark for Text-to-SQL' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Did%20You%20Ask%20a%20Good%20Question?%20A%20Cross-Domain%20Question%20Intention%20Classification%20Benchmark%20for%20Text-to-SQL' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Yusen Zhang, Xiangyu Dong, Shuaichen Chang, Tao Yu, Peng Shi, Rui Zhang</td>
	<td></td>
	<td><p>Neural models have achieved significant results on the text-to-SQL task, in which most current work assumes all the input questions are legal and generates a SQL query for any input. However, in the real scenario, users can input any text that may not be able to be answered by a SQL query. In this work, we propose TriageSQL, the first cross-domain text-to-SQL question intention classification benchmark that requires models to distinguish four types of unanswerable questions from answerable questions. The baseline RoBERTa model achieves a 60% F1 score on the test set, demonstrating the need for further improvement on this task. Our dataset is available at this URL: https://github.com/chatc/TriageSQL</p>
</td>
	<td>sql cross-domain dataset </td>
</tr>



<tr>
	<td>2019</td>
	<td><a href="/publications/yu2019cosql/">CoSQL: A Conversational Text-to-SQL Challenge Towards Cross-Domain Natural Language Interfaces to Databases</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=CoSQL: A Conversational Text-to-SQL Challenge Towards Cross-Domain Natural Language Interfaces to Databases' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=CoSQL: A Conversational Text-to-SQL Challenge Towards Cross-Domain Natural Language Interfaces to Databases' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=CoSQL:%20A%20Conversational%20Text-to-SQL%20Challenge%20Towards%20Cross-Domain%20Natural%20Language%20Interfaces%20to%20Databases' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Tao Yu, Rui Zhang, He Yang Er, Suyi Li, Eric Xue, Bo Pang, Xi Victoria Lin, Yi Chern Tan, Tianze Shi, Zihan Li, Youxuan Jiang, Michihiro Yasunaga, Sungrok Shim, Tao Chen, Alexander Fabbri, Zifan Li, Luyao Chen, Yuwen Zhang, Shreya Dixit, Vincent Zhang, Caiming Xiong, Richard Socher, Walter S Lasecki, Dragomir Radev</td>
	<td>EMNLP</td>
	<td><p>We present CoSQL, a corpus for building cross-domain, general-purpose database (DB) querying dialogue systems. It consists of 30k+ turns plus 10k+ annotated SQL queries, obtained from a Wizard-of-Oz (WOZ) collection of 3k dialogues querying 200 complex DBs spanning 138 domains. Each dialogue simulates a real-world DB query scenario with a crowd worker as a user exploring the DB and a SQL expert retrieving answers with SQL, clarifying ambiguous questions, or otherwise informing of unanswerable questions. When user questions are answerable by SQL, the expert describes the SQL and execution results to the user, hence maintaining a natural interaction flow. CoSQL introduces new challenges compared to existing task-oriented dialogue datasets:(1) the dialogue states are grounded in SQL, a domain-independent executable representation, instead of domain-specific slot-value pairs, and (2) because testing is done on unseen databases, success requires generalizing to new domains. CoSQL includes three tasks: SQL-grounded dialogue state tracking, response generation from query results, and user dialogue act prediction. We evaluate a set of strong baselines for each task and show that CoSQL presents significant challenges for future research. The dataset, baselines, and leaderboard will be released at this URL: https://yale-lily.github.io/cosql</p>
</td>
	<td>sql cross-domain conversational dataset </td>
</tr>

<tr>
	<td>2019</td>
	<td><a href="/publications/yu2019sparc/">SParC: Cross-Domain Semantic Parsing in Context</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=SParC: Cross-Domain Semantic Parsing in Context' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=SParC: Cross-Domain Semantic Parsing in Context' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=SParC:%20Cross-Domain%20Semantic%20Parsing%20in%20Context' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Tao Yu, Rui Zhang, Michihiro Yasunaga, Yi Chern Tan, Xi Victoria Lin, Suyi Li, Heyang Er, Irene Li, Bo Pang, Tao Chen, Emily Ji, Shreya Dixit, David Proctor, Sungrok Shim, Jonathan Kraft, Vincent Zhang, Caiming Xiong, Richard Socher, Dragomir Radev</td>
	<td>ACL</td>
	<td><p>We present SParC, a dataset for cross-domain SemanticParsing in Context that consists of 4,298 coherent question sequences (12k+ individual questions annotated with SQL queries). It is obtained from controlled user interactions with 200 complex databases over 138 domains. We provide an in-depth analysis of SParC and show that it introduces new challenges compared to existing datasets. SParC demonstrates complex contextual dependencies, (2) has greater semantic diversity, and (3) requires generalization to unseen domains due to its cross-domain nature and the unseen databases at test time. We experiment with two state-of-the-art text-to-SQL models adapted to the context-dependent, cross-domain setup. The best model obtains an exact match accuracy of 20.2% over all questions and less than10% over all interaction sequences, indicating that the cross-domain setting and the con-textual phenomena of the dataset present significant challenges for future research. The dataset, baselines, and leaderboard are released at this URL: https://yale-lily.github.io/sparc</p>
</td>
	<td>sql cross-domain conversational dataset </td>
</tr>

<tr>
	<td>2019</td>
	<td><a href="/publications/chen2019hybridqa/">HybridQA: A Dataset of Multi-Hop Question Answering over Tabular and Textual Data</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=HybridQA: A Dataset of Multi-Hop Question Answering over Tabular and Textual Data' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=HybridQA: A Dataset of Multi-Hop Question Answering over Tabular and Textual Data' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=HybridQA:%20A%20Dataset%20of%20Multi-Hop%20Question%20Answering%20over%20Tabular%20and%20Textual%20Data' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Wenhu Chen, Hanwen Zha, Zhiyu Chen, Wenhan Xiong, Hong Wang, William Wang</td>
	<td>EMNLP</td>
	<td><p>Existing question answering datasets focus on dealing with homogeneous information, based either only on text or KB/Table information alone. However, as human knowledge is distributed over heterogeneous forms, using homogeneous information alone might lead to severe coverage problems. To fill in the gap, we present HybridQA this https URL, a new large-scale question-answering dataset that requires reasoning on heterogeneous information. Each question is aligned with a Wikipedia table and multiple free-form corpora linked with the entities in the table. The questions are designed to aggregate both tabular information and text information, i.e., lack of either form would render the question unanswerable. We test with three different models: 1) a table-only model. 2) text-only model. 3) a hybrid model that combines heterogeneous information to find the answer. The experimental results show that the EM scores obtained by two baselines are below 20\%, while the hybrid model can achieve an EM over 40\%. This gap suggests the necessity to aggregate heterogeneous information in HybridQA. However, the hybrid model’s score is still far behind human performance. Hence, HybridQA can serve as a challenging benchmark to study question answering with heterogeneous information.</p>
</td>
	<td>sql dataset </td>
</tr>



<tr>
	<td>2018</td>
	<td><a href="/publications/dollak2018improving/">Improving Text-to-SQL Evaluation Methodology</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Improving Text-to-SQL Evaluation Methodology' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Improving Text-to-SQL Evaluation Methodology' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Improving%20Text-to-SQL%20Evaluation%20Methodology' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Catherine Finegan-Dollak, Jonathan K. Kummerfeld, Li Zhang, Karthik Ramanathan, Sesh Sadasivam, Rui Zhang, Dragomir Radev</td>
	<td>ACL</td>
	<td><p>To be informative, an evaluation must measure how well systems generalize to realistic unseen data. We identify limitations of and propose improvements to current evaluations of text-to-SQL systems. First, we compare human-generated and automatically generated questions, characterizing properties of queries necessary for real-world applications. To facilitate evaluation on multiple datasets, we release standardized and improved versions of seven existing datasets and one new text-to-SQL dataset. Second, we show that the current division of data into training and test sets measures robustness to variations in the way questions are asked, but only partially tests how well systems generalize to new queries; therefore, we propose a complementary dataset split for evaluation of future work. Finally, we demonstrate how the common practice of anonymizing variables during evaluation removes an important challenge of the task. Our observations highlight key difficulties, and our methodology enables effective measurement of future development.</p>
</td>
	<td>sql dataset </td>
</tr>

<tr>
	<td>2018</td>
	<td><a href="/publications/yu2018spider/">Spider: A Large-Scale Human-Labeled Dataset for Complex and Cross-Domain Semantic Parsing and Text-to-SQL Task</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Spider: A Large-Scale Human-Labeled Dataset for Complex and Cross-Domain Semantic Parsing and Text-to-SQL Task' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Spider: A Large-Scale Human-Labeled Dataset for Complex and Cross-Domain Semantic Parsing and Text-to-SQL Task' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Spider:%20A%20Large-Scale%20Human-Labeled%20Dataset%20for%20Complex%20and%20Cross-Domain%20Semantic%20Parsing%20and%20Text-to-SQL%20Task' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Tao Yu, Rui Zhang, Kai Yang, Michihiro Yasunaga, Dongxu Wang, Zifan Li, James Ma, Irene Li, Qingning Yao, Shanelle Roman, Zilin Zhang, Dragomir Radev</td>
	<td>EMNLP</td>
	<td><p>We present Spider, a large-scale, complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 college students. It consists of 10,181 questions and 5,693 unique complex SQL queries on 200 databases with multiple tables, covering 138 different domains. We define a new complex and cross-domain semantic parsing and text-to-SQL task where different complex SQL queries and databases appear in train and test sets. In this way, the task requires the model to generalize well to both new SQL queries and new database schemas. Spider is distinct from most of the previous semantic parsing tasks because they all use a single database and the exact same programs in the train set and the test set. We experiment with various state-of-the-art models and the best model achieves only 12.4% exact matching accuracy on a database split setting. This shows that Spider presents a strong challenge for future research. Our dataset and task are publicly available at this URL: https://yale-lily.github.io/spider</p>
</td>
	<td>sql cross-domain dataset </td>
</tr>



<tr>
	<td>2017</td>
	<td><a href="/publications/zhong2017seq2sql/">Seq2SQL: Generating Structured Queries from Natural Language using Reinforcement Learning</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Seq2SQL: Generating Structured Queries from Natural Language using Reinforcement Learning' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Seq2SQL: Generating Structured Queries from Natural Language using Reinforcement Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Seq2SQL:%20Generating%20Structured%20Queries%20from%20Natural%20Language%20using%20Reinforcement%20Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Victor Zhong, Caiming Xiong, Richard Socher</td>
	<td></td>
	<td><p>A significant amount of the world’s knowledge is stored in relational databases. However, the ability for users to retrieve facts from a database is limited due to a lack of understanding of query languages such as SQL. We propose Seq2SQL, a deep neural network for translating natural language questions to corresponding SQL queries. Our model leverages the structure of SQL queries to significantly reduce the output space of generated queries. Moreover, we use rewards from in-the-loop query execution over the database to learn a policy to generate unordered parts of the query, which we show are less suitable for optimization via cross entropy loss. In addition, we will publish WikiSQL, a dataset of 80654 hand-annotated examples of questions and SQL queries distributed across 24241 tables from Wikipedia. This dataset is required to train our model and is an order of magnitude larger than comparable datasets. By applying policy-based reinforcement learning with a query execution environment to WikiSQL, our model Seq2SQL outperforms attentional sequence to sequence models, improving execution accuracy from 35.9% to 59.4% and logical form accuracy from 23.4% to 48.3%.</p>
</td>
	<td>sql cross-domain dataset reinforcement-learning </td>
</tr>


</tbody></table>

<script>
var datatable;

function searchTable() {
    var hash = decodeURIComponent(window.location.hash.substr(1));
    datatable.search(hash).draw();
}


$(document).ready( function () {
    datatable = $('#allPapers').DataTable({
		paging: false,
		"order": [[ 0, 'desc' ], [ 1, 'asc' ]],
		columnDefs: [
			{
				targets: [3, 4, 5],
				visible: false,
				searchable: true
			}]
		});
    searchTable();
});

$(window).on('hashchange', function() {
  searchTable();
});
</script>


    </div>

  </body>
</html>
